Project Outline:

Clustering:

1) Compare two columns -- find the correlation between variables we are curious about and happiness.
2) Visualize the relationship i.e. happiness on one axis vs. other variable.
3) Choose variables -- look at the distribution of correlation values, because we want to figure out the threshold for where we choose to include a variable.
	* Can look at the distribution and make a good enough estimate of which ones seem more highly correlated.
	* Eliminate variables that have nothing to do with happiness.
4) Subset to just the relevant columns (to happiness)
5) Then perform the clustering using the relevant columns.
	Can use 2 or more columns to create the clusters.
	** Point of clustering is to find out how close two things are to each other. Based on the software package, will calculate distance between countries based on all the columns. K-means clustering, where K is the number of clusters. Choosing the value of K is a whole art in itself. NLP lecture there is a part where Eric talks about a silhouette metric, which is a measure of how good your cluster is. Look at that as a way to choose how many clusters. Helps us choose what K to use. Once we have a number chosen, then we can ask what makes these clusters? Used variables to create clusters, so ask what each cluster has in common? What makes the items in cluster 1 similar? Cluster 2, etc. etc. 
	Side note: K-means... if you compare countries by clustering, you need numerical values, so convert the string values to numbers. Algorithm only works on numbers.
6) If you figure out how the clusters are related to each other, that is a "cluster label". Then compare the happiness score of each country in the cluster to see if the factors that make up the label correlate to happiness. 

Note: Clustering is kind of exploratory

Prediction piece:

Choose what algorithm to pair happiness and other variables together, then see how the model does. Linear regression will give us a coefficient for each variable, which will tell us how important the variable is to predicting happiness. Side note: Briefly look into preprocessing data at this point (?) normalizing data before putting into a model (read about preprocessing and normalization and whether it impacts unsupervised learning -- but it will definitely impact supervised learning.) Example in out data -- litres of alcohol vs. servings, because the numbers are so different. We don't want the model to weigh variables more heavily because they have higher values in general. Find which variables matter the most in predicting happiness. 